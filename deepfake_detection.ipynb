{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb1e24e-a93c-4a74-8335-cf1562f0abaf",
   "metadata": {},
   "source": [
    "# Gerekli kütüphanelerin import'u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860e8b6f-c7ee-4fd2-9a6f-e54d425f2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d0e0f-6dc1-4bfd-94cb-815205e5661f",
   "metadata": {},
   "source": [
    "# Gerekli fonksiyonların tanımlanması"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdedb3ae-19da-4281-8276-7214a4c83317",
   "metadata": {},
   "source": [
    "Video dosyalarını karelere ayıran fonksiyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee3233f-6e74-457a-b7a8-b56f0bc25e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    frames = []\n",
    "    while success:\n",
    "        frames.append(image)\n",
    "        success, image = vidcap.read()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9761b-51ef-4051-b5a9-77fb2ea09965",
   "metadata": {},
   "source": [
    "Karelerdeki yüzleri tespit eden ve kırpan fonksiyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01dc93dc-dae3-4f4a-99ab-484449e3a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(image):\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    cropped_faces = []\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image[top:bottom, left:right]\n",
    "        face_image = cv2.resize(face_image, (64, 64))\n",
    "        cropped_faces.append(face_image)\n",
    "    return cropped_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727455a-8365-49a8-a209-4625c52b7f5d",
   "metadata": {},
   "source": [
    "JSON Dosyasını kullanarak veriyi yükleme fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e7902e-34d0-4856-83c5-e4ecc31824aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_json(json_path, video_folder):\n",
    "    with open(json_path, 'r') as file:\n",
    "        data_info = json.load(file)\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for video_name, info in data_info.items():\n",
    "        video_path = os.path.join(video_folder, video_name)\n",
    "        \n",
    "        # Videoyu karelere ayır\n",
    "        frames = video_to_frames(video_path)\n",
    "        \n",
    "        # Karelerdeki yüzleri kırp\n",
    "        for frame in frames:\n",
    "            cropped_faces = detect_and_crop_faces(frame)\n",
    "        \n",
    "            # Kırpılmış yüzleri yükle\n",
    "            for face_image in cropped_faces:\n",
    "                if face_image is not None:\n",
    "                    data.append(face_image)\n",
    "                    labels.append(1 if info['label'] == 'FAKE' else 0)\n",
    "    \n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93edcf1-631b-4c13-ad09-839d5ebb8e5c",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks(CNN) modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39e178-02dd-401b-9d7f-783e975ca0db",
   "metadata": {},
   "source": [
    "Modelin oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b800a5-803d-4a44-b5e8-3e3b0a0f7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6f7de-c7c3-4869-b95b-34a501cb340f",
   "metadata": {},
   "source": [
    "Model eğitme fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61c5d6e-9972-4241-bc4a-908a55f3d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(json_path, video_folder):\n",
    "    # Veriyi yükle\n",
    "    data, labels = load_data_from_json(json_path, video_folder)\n",
    "\n",
    "    # Veriyi eğitim ve test setlerine ayır\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Model checkpoint callback\n",
    "    checkpoint_path = \"model_checkpoint.h5\"\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "     \n",
    "    # Eğer checkpoint olarak .h5 dosyası var ise yükle, yoksa yeni model oluştur\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model = load_model(checkpoint_path)\n",
    "        print(\"Checkpoint yüklendi.\")\n",
    "    else:\n",
    "        model = create_cnn_model()        \n",
    "        # fit fonksiyonu ile veriyi göndererek modeli eğit\n",
    "        model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "        print(\"Yeni model oluşturuldu.\")\n",
    "\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525b04f-5ad4-489c-af75-a8d769bbcaaa",
   "metadata": {},
   "source": [
    "TensorFlow GPU kullanımını etkinleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d781a6e-c9f8-4263-bb44-032b3aeb3fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Tüm GPU'ları kullan\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Hata durumunda yazdır\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805de94-c2ec-4150-9b1f-d6a2a537bb8c",
   "metadata": {},
   "source": [
    "Modeli Eğitme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db3ab3a-8966-416d-afaa-0029ab3893b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 4.1906 - accuracy: 0.8631\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96914, saving model to model_checkpoint.h5\n",
      "91/91 [==============================] - 3s 8ms/step - loss: 3.9159 - accuracy: 0.8696 - val_loss: 0.0819 - val_accuracy: 0.9691\n",
      "Epoch 2/10\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 0.0481 - accuracy: 0.9864\n",
      "Epoch 2: val_accuracy improved from 0.96914 to 0.97538, saving model to model_checkpoint.h5\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9865 - val_loss: 0.0668 - val_accuracy: 0.9754\n",
      "Epoch 3/10\n",
      "86/91 [===========================>..] - ETA: 0s - loss: 0.0288 - accuracy: 0.9913\n",
      "Epoch 3: val_accuracy improved from 0.97538 to 0.98301, saving model to model_checkpoint.h5\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0478 - val_accuracy: 0.9830\n",
      "Epoch 4/10\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.0087 - accuracy: 0.9978\n",
      "Epoch 4: val_accuracy improved from 0.98301 to 0.99307, saving model to model_checkpoint.h5\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0255 - val_accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "87/91 [===========================>..] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 5: val_accuracy improved from 0.99307 to 0.99480, saving model to model_checkpoint.h5\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0183 - val_accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "83/91 [==========================>...] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 6: val_accuracy improved from 0.99480 to 0.99619, saving model to model_checkpoint.h5\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "84/91 [==========================>...] - ETA: 0s - loss: 2.2149e-04 - accuracy: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 0.99619\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1598e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "85/91 [===========================>..] - ETA: 0s - loss: 1.3144e-04 - accuracy: 1.0000\n",
      "Epoch 8: val_accuracy did not improve from 0.99619\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 1.2741e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9958\n",
      "Epoch 9/10\n",
      "79/91 [=========================>....] - ETA: 0s - loss: 8.2818e-05 - accuracy: 1.0000\n",
      "Epoch 9: val_accuracy did not improve from 0.99619\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 8.1135e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9958\n",
      "Epoch 10/10\n",
      "80/91 [=========================>....] - ETA: 0s - loss: 6.2590e-05 - accuracy: 1.0000\n",
      "Epoch 10: val_accuracy did not improve from 0.99619\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.1387e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "model, X_test, y_test = train_model('data/videos/metadata.json', 'data/videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b077b1-92f7-4252-83fd-d7c9906b185e",
   "metadata": {},
   "source": [
    "Modeli değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e06893-f8c3-431e-b1f0-df3b45b6eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       1.00      1.00      1.00      1603\n",
      "        Fake       1.00      0.99      0.99      1281\n",
      "\n",
      "    accuracy                           1.00      2884\n",
      "   macro avg       1.00      1.00      1.00      2884\n",
      "weighted avg       1.00      1.00      1.00      2884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    print(classification_report(y_test, predictions, target_names=[\"Real\", \"Fake\"]))\n",
    "    \n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc26c5-59c3-417f-9abf-ca51e1221a63",
   "metadata": {},
   "source": [
    "Spesifik video hakkında tahmin yürütme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a868c92-0427-4cc8-9198-9e06c266d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 27ms/step\n",
      "Video: data/specific_tests/f1.mp4, fake.\n"
     ]
    }
   ],
   "source": [
    "# Spesifik test videoları\n",
    "test_videos = ['data/specific_tests/f1.mp4','data/specific_tests/f2.mp4','data/specific_tests/f3.mp4','data/specific_tests/r1.mp4','data/specific_tests/r2.mp4']\n",
    "# Eğitilmiş modelin yolu\n",
    "model_path = 'model_checkpoint.h5'\n",
    "\n",
    "def load_and_preprocess_video(video_path):\n",
    "    # Videoyu karelere ayır\n",
    "    frames = video_to_frames(video_path)\n",
    "    \n",
    "    # Karelerdeki yüzleri kırp ve preprocess et\n",
    "    faces = []\n",
    "    for frame in frames:\n",
    "        cropped_faces = detect_and_crop_faces(frame)\n",
    "        for face in cropped_faces:\n",
    "            faces.append(face)\n",
    "    \n",
    "    # Yüzleri numpy array'e çevir\n",
    "    faces = np.array(faces)\n",
    "    return faces\n",
    "def predict_video(video_path, model_path):\n",
    "    # Videodan yüzleri yükle\n",
    "    faces = load_and_preprocess_video(video_path)\n",
    "    \n",
    "    # Eğitilmiş modeli yükle\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Yüzler üzerinde tahmin yap\n",
    "    predictions = model.predict(faces)\n",
    "    \n",
    "    # Tahmin sonuçlarını analiz et\n",
    "    fake_count = np.sum(predictions > 0.5)\n",
    "    real_count = np.sum(predictions <= 0.5)\n",
    "    \n",
    "    if fake_count > real_count:\n",
    "        print(f\"Video: {video_path}, fake.\")\n",
    "    else:\n",
    "        print(f\"Video: {video_path}, gerçek.\")\n",
    "\n",
    "predict_video(test_videos[0], model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce19150-2ce6-4149-a571-0b271b10ce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
